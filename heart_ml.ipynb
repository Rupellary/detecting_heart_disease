{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dectecting Heart Disease Machine Learning Project"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Citation:\n",
    "This project uses data from the UCI Machine Learning Repository\n",
    "\n",
    "\n",
    "Janosi,Andras, Steinbrunn,William, Pfisterer,Matthias, and Detrano,Robert. (1988). Heart Disease. UCI Machine Learning Repository. https://doi.org/10.24432/C52P4X."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Imports"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing Libraries\n",
    "\n",
    "# Custom Functions\n",
    "from heart_ml_utils.py import *\n",
    "\n",
    "# Data Exploration and Plotting\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "import numpy as np\n",
    "import math\n",
    "\n",
    "# Pipelining\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import OneHotEncoder, OrdinalEncoder, StandardScaler, RobustScaler, MinMaxScaler\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "\n",
    "# Modeling\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.ensemble import RandomForestClassifier, GradientBoostingClassifier\n",
    "\n",
    "# Scoring\n",
    "from sklearn.metrics import confusion_matrix, roc_auc_score, roc_curve, precision_recall_curve, accuracy_score, precision_score, recall_score, f1_score, ConfusionMatrixDisplay"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "feat_names = ['age', # (numerical)\n",
    "              'sex', # (binary)\n",
    "              'cp', # (categorical) [1-4] chest pain \n",
    "              'trestbps', # (numerical) resting blood pressure \n",
    "              'chol', # (numerical) serum cholestoral in mg/dl \n",
    "              'fbs', # (binary) fasting blood sugar > 120 mg/dl \n",
    "              'restecg', # (ordinal)(pre-encoded) [0-2] resting electrocardiographic results \n",
    "              'thalach', # (numerical) maximum heart rate acheived \n",
    "              'exang', # (binary) exercised induced angina \n",
    "              'oldpeak', # (numerical) ST depression induced by exercise relative to rest \n",
    "              'slope', # (ordinal)(pre-encoded) [1-3] slope of the peak exercise ST segment\n",
    "              'ca', # (numerical) number of major vessels colored by flourosopy\n",
    "              'thal', # (ordinal)(pre-encoded) \"3 = normal; 6 = fixed defect; 7 = reversable defect\"\n",
    "              'num'] # (categorical) [0-4] diagnosis \n",
    "heart_df = pd.read_csv('cleveland_heart_data', names = feat_names)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Cleaning and Feature Engineering"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "dropped 3.3% of data\n"
     ]
    }
   ],
   "source": [
    "# Drop observations with problematic values (see heart_ml_data_explor.ipynb)\n",
    "\n",
    "cleaned_df = heart_df\n",
    "\n",
    "# Create a dictionary of column-value pairs for flexible alteration\n",
    "drop_dict = {'restecg':1,\n",
    "             'ca':'?',\n",
    "             'thal':'?'\n",
    "}\n",
    "\n",
    "# Drop data according to dictionary\n",
    "for drop_col in list(drop_dict.keys()):\n",
    "    cleaned_df = drop_data(cleaned_df, drop_col, drop_dict[drop_col]) #using custom function (see heart_ml_utils.py)   \n",
    "\n",
    "print(f'dropped {round((heart_df.shape[0] - cleaned_df.shape[0])*100 / heart_df.shape[0],2)}% of data')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "ca\n",
      "thal\n"
     ]
    }
   ],
   "source": [
    "# ALTERNATIVELY: Replace ?s with None to be imputed later\n",
    "\n",
    "cleaned_df = heart_df\n",
    "\n",
    "cleaned_df = string_to_Na(cleaned_df, '?') #using custom function (see heart_ml_utils.py)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the ?s have been dealt with the columns must be converted from object to float\n",
    "\n",
    "# Create a dictionary of column-type pairs for flexible alteration\n",
    "dtype_dict = {'ca':'float',\n",
    "              'thal':'float'\n",
    "}\n",
    "\n",
    "# Convert columns into new data types according to dictionary\n",
    "for col in list(dtype_dict.keys()):\n",
    "    cleaned_df[col] = cleaned_df[col].astype(dtype_dict[col])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Rather than predicting specific diseases, this model will classify between diseased and healthy\n",
    "\n",
    "cleaned_df['num'] = 0\n",
    "cleaned_df.loc[cleaned_df['num']>0, 'num'] = 1\n",
    "# 0 means healthy, 1 means diseased"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "# OPTIONAL: Consider using this binary version later (depending on the type of model)\n",
    "\n",
    "extra_feature_df = cleaned_df\n",
    "extra_feature_df['st_no_change'] = 0\n",
    "extra_feature_df.loc[extra_feature_df['oldpeak']>0, 'st_no_change'] = 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Splitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Separate Predictor Features (X) and Target Feature (y)\n",
    "X = cleaned_df # OPTIONAL: switch with extra_feature_df\n",
    "y = X.pop('num')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate Test Data From Training Data\n",
    "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Preprocessing Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Seperate features by data type for preprocessing pipeline\n",
    "categorical_features = ['cp']\n",
    "\n",
    "# OPTIONAL: Identify ordinally pre-ecoded features to test onehot encoding instead\n",
    "ordinal_features = ['restecg', 'slope', 'thal']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Choices to try adjusting when testing the models**\n",
    "* do not remove as much data\n",
    "* use binary version of oldpeak\n",
    "* onehot encode features currently ordinally pre-encoded"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "base",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
